{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_a: df de amazon <br>\n",
    "df_d: df de disney<br>\n",
    "df_n: df de netflix<br>\n",
    "df_h: df de hulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a= pd.read_csv('Datasets/amazon_prime_titles.csv')\n",
    "df_d= pd.read_csv('Datasets/disney_plus_titles.csv')\n",
    "df_n= pd.read_json('Datasets/netflix_titles.json')\n",
    "df_h= pd.read_csv('Datasets/hulu_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista con los df para iterar en los distintos procesos\n",
    "dfs = [df_a,df_d,df_n,df_h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los criterio de la limpieza y pre-porcesamiento de los datos lo hice en base a las consultas que quiero responder.\n",
    "\n",
    "Las consultas a realizar son:\n",
    "\n",
    "+ Máxima duración según tipo de film (película/serie), por plataforma y por año:\n",
    "    El request debe ser: get_max_duration(año, plataforma, [min o season])\n",
    "\n",
    "+ Cantidad de películas y series (separado) por plataforma\n",
    "    El request debe ser: get_count_plataform(plataforma)  \n",
    "  \n",
    "+ Cantidad de veces que se repite un género y plataforma con mayor frecuencia del mismo.\n",
    "    El request debe ser: get_listedin('genero')  \n",
    "    Como ejemplo de género pueden usar 'comedy', el cuál deberia devolverles un cunt de 2099 para la plataforma de amazon.\n",
    "\n",
    "+ Actor que más se repite según plataforma y año.\n",
    "  El request debe ser: get_actor(plataforma, año)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizo los datos que tengo:<br>\n",
    "    - si el tipo de dato coincide con el Dtype\n",
    "    - exitencia de conflicto entre los df\n",
    "    - cantidad de valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los df comparten las mismas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9668 entries, 0 to 9667\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   show_id       9668 non-null   object\n",
      " 1   type          9668 non-null   object\n",
      " 2   title         9668 non-null   object\n",
      " 3   director      7585 non-null   object\n",
      " 4   cast          8435 non-null   object\n",
      " 5   country       672 non-null    object\n",
      " 6   date_added    155 non-null    object\n",
      " 7   release_year  9668 non-null   int64 \n",
      " 8   rating        9331 non-null   object\n",
      " 9   duration      9668 non-null   object\n",
      " 10  listed_in     9668 non-null   object\n",
      " 11  description   9668 non-null   object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 906.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1450 entries, 0 to 1449\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   show_id       1450 non-null   object\n",
      " 1   type          1450 non-null   object\n",
      " 2   title         1450 non-null   object\n",
      " 3   director      977 non-null    object\n",
      " 4   cast          1260 non-null   object\n",
      " 5   country       1231 non-null   object\n",
      " 6   date_added    1447 non-null   object\n",
      " 7   release_year  1450 non-null   int64 \n",
      " 8   rating        1447 non-null   object\n",
      " 9   duration      1450 non-null   object\n",
      " 10  listed_in     1450 non-null   object\n",
      " 11  description   1450 non-null   object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 136.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8807 entries, 0 to 8806\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   show_id       8807 non-null   object\n",
      " 1   type          8807 non-null   object\n",
      " 2   title         8807 non-null   object\n",
      " 3   director      6173 non-null   object\n",
      " 4   cast          7982 non-null   object\n",
      " 5   country       7976 non-null   object\n",
      " 6   date_added    8797 non-null   object\n",
      " 7   release_year  8807 non-null   int64 \n",
      " 8   rating        8803 non-null   object\n",
      " 9   duration      8804 non-null   object\n",
      " 10  listed_in     8807 non-null   object\n",
      " 11  description   8807 non-null   object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 894.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_n.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna 'cast' tiene Dtype float64, cuando deberia ser object.\n",
    "Además que no tiene datos por lo que cambaire lso ceros a 'Sin datos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3073 entries, 0 to 3072\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   show_id       3073 non-null   object \n",
      " 1   type          3073 non-null   object \n",
      " 2   title         3073 non-null   object \n",
      " 3   director      3 non-null      object \n",
      " 4   cast          0 non-null      float64\n",
      " 5   country       1620 non-null   object \n",
      " 6   date_added    3045 non-null   object \n",
      " 7   release_year  3073 non-null   int64  \n",
      " 8   rating        2553 non-null   object \n",
      " 9   duration      2594 non-null   object \n",
      " 10  listed_in     3073 non-null   object \n",
      " 11  description   3069 non-null   object \n",
      "dtypes: float64(1), int64(1), object(10)\n",
      "memory usage: 288.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_h.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h['cast'] = df_h['cast'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conflicto en show_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los show_id de las ditintas plataformas se repiten por los que para evitar conficiones le agrego la letres de si plataforma delante del número. Ademas le quito la 's' que tiene delante del id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "letras = ['a','d','n','h']\n",
    "#itera sobre los df en dfs y agrega la letra corespondiente a la plataforma usando el index de dfs.\n",
    "for i,df in enumerate(dfs):\n",
    "    df['show_id'] = df['show_id'].map(lambda x: letras[i]+x[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doy formato a los datos que estan mal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La columna 'duration' expresa la duracion de las peliculas en min o la cantidad de de temporadas si es una serie. <br>\n",
    "Como es una varialbe cuantitativa discreta le cambio el Dtye a int64, para ello tengo que eliminar el 'min' y 'Season' o 'Seasons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion que deja solo la parte numerica de la columna 'duration'\n",
    "def limpiar_datos_num(df):\n",
    "    #df: dataframe que se va a limpiar\n",
    "    \n",
    "    #esta funcion elimina 'min' o 'Seasons' segun si es duracion en min o temporadas.\n",
    "    def limp_segun_duracion(duracion):\n",
    "        #verifico los que sean un valor nulo y los cambio por cero.\n",
    "        if duracion == None or duracion == 'nan':\n",
    "            return '0'\n",
    "        #en caso de que la varible se float la vulevo str y la vuelvo a evaluar\n",
    "        elif type(duracion) == float:\n",
    "             return limp_segun_duracion(str(duracion))\n",
    "        elif 'min' in duracion:\n",
    "            return duracion[:-3]\n",
    "        else:\n",
    "            return duracion[:-7]\n",
    "    #aplica limp_segun_duracion en la columna 'duration' mediante mapeo\n",
    "    df['duration'] = df['duration'].map(lambda x:limp_segun_duracion(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "limpiar_datos_num(df_a)\n",
    "limpiar_datos_num(df_d)\n",
    "limpiar_datos_num(df_n)\n",
    "limpiar_datos_num(df_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambio el Dtype de la columna 'duration' y 'release_year' a uint16 por ser valores positivos menores al maximo permitido de ese tipo (65535). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dar_formato(df):\n",
    "    columns_int =['release_year','duration']\n",
    "    \n",
    "    for col in columns_int:\n",
    "        df[col] = df[col].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dar_formato(df_a)\n",
    "dar_formato(df_d)\n",
    "dar_formato(df_n)\n",
    "dar_formato(df_h)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conseguir_val_unicos(df,col):\n",
    "    '''\n",
    "    df: dataframe \n",
    "    col: str del nimbre de la columna del df \n",
    "\n",
    "    Devulve los valores unicos de la columna en formato Serie de pandas.\n",
    "    '''\n",
    "\n",
    "    valores=[]\n",
    "    lista_valores = []\n",
    "    valores_df = df[col].values\n",
    "    \n",
    "    #llena lista_valores con listas del reparto de cada pelicula\n",
    "    for val in valores_df:\n",
    "        if type(val) == str:\n",
    "            \n",
    "            lista_valores.append(str.split(val,','))\n",
    "\n",
    "    #llena valores con los actores\n",
    "    for lista in lista_valores:\n",
    "        for val in lista:\n",
    "            valores.append(val.lstrip())#utlizo ltrip porque hay valores con un espacio delante\n",
    "    \n",
    "    #convierte la lista en una serie de pandas y elimina los repetidos\n",
    "    valores = pd.Series(valores)\n",
    "    valores = valores.drop_duplicates()\n",
    "    return valores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valores_col(lista_df,col):\n",
    "    '''\n",
    "    lista_df: lista de dataframes\n",
    "    col: str\n",
    "\n",
    "    Devuelve los valores unicos de todos los dataframes en lista_df de la columna col\n",
    "    '''\n",
    "    #serie vacia\n",
    "    valores_col=pd.Series()\n",
    "\n",
    "    #llena valores_col \n",
    "    for df in lista_df:\n",
    "        valores_col=pd.concat([valores_col, conseguir_val_unicos(df,col)])\n",
    "    \n",
    "    # elimino los valores repetidos\n",
    "    valores_col.drop_duplicates(inplace=True)\n",
    "    #ordeno la lista\n",
    "    valores_col.sort_values(inplace=True)\n",
    "    return valores_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Normalizando la columna 'listed_in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enlisto las distintas categorias de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria =  valores_col([df_a,df_d,df_n,df_h],'listed_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Action', 'Action & Adventure', 'Action-Adventure',\n",
       "       'Adult Animation', 'Adventure', 'Animals & Nature', 'Animation',\n",
       "       'Anime', 'Anime Features', 'Anime Series', 'Anthology', 'Arthouse',\n",
       "       'Arts', 'Biographical', 'Black Stories', 'British TV Shows',\n",
       "       'Buddy', 'Cartoons', 'Children & Family Movies',\n",
       "       'Classic & Cult TV', 'Classic Movies', 'Classics', 'Comedies',\n",
       "       'Comedy', 'Coming of Age', 'Concert Film', 'Cooking & Food',\n",
       "       'Crime', 'Crime TV Shows', 'Cult Movies', 'Dance', 'Disaster',\n",
       "       'Documentaries', 'Documentary', 'Docuseries', 'Drama', 'Dramas',\n",
       "       'Entertainment', 'Faith & Spirituality', 'Faith and Spirituality',\n",
       "       'Family', 'Fantasy', 'Fitness', 'Game Show / Competition',\n",
       "       'Game Shows', 'Health & Wellness', 'Historical', 'History',\n",
       "       'Horror', 'Horror Movies', 'Independent Movies', 'International',\n",
       "       'International Movies', 'International TV Shows', 'Kids',\n",
       "       \"Kids' TV\", 'Korean TV Shows', 'LGBTQ', 'LGBTQ Movies', 'LGBTQ+',\n",
       "       'Late Night', 'Latino', 'Lifestyle', 'Lifestyle & Culture',\n",
       "       'Medical', 'Military and War', 'Movies', 'Music',\n",
       "       'Music & Musicals', 'Music Videos and Concerts', 'Musical',\n",
       "       'Mystery', 'News', 'Parody', 'Police/Cop', 'Reality', 'Reality TV',\n",
       "       'Romance', 'Romantic Comedy', 'Romantic Movies',\n",
       "       'Romantic TV Shows', 'Sci-Fi & Fantasy', 'Science & Nature TV',\n",
       "       'Science & Technology', 'Science Fiction', 'Series', 'Sitcom',\n",
       "       'Sketch Comedy', 'Soap Opera / Melodrama',\n",
       "       'Spanish-Language TV Shows', 'Special Interest', 'Sports',\n",
       "       'Sports Movies', 'Spy/Espionage', 'Stand Up', 'Stand-Up Comedy',\n",
       "       'Stand-Up Comedy & Talk Shows', 'Superhero', 'Survival',\n",
       "       'Suspense', 'TV Action & Adventure', 'TV Comedies', 'TV Dramas',\n",
       "       'TV Horror', 'TV Mysteries', 'TV Sci-Fi & Fantasy', 'TV Shows',\n",
       "       'TV Thrillers', 'Talk Show', 'Talk Show and Variety', 'Teen',\n",
       "       'Teen TV Shows', 'Thriller', 'Thrillers', 'Travel', 'Unscripted',\n",
       "       'Variety', 'Western', 'Young Adult Audience', 'and Culture'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoria.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta seria la normalizacion para categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_normalizar ={'Action & Adventure':['Action-Adventure','TV Action & Adventure'],\n",
    "                    'Anime':['Animation','Anime', 'Anime Features', 'Anime Series'],\n",
    "                    'Classic':['Classic & Cult TV', 'Classic Movies', 'Classics'],\n",
    "                    'Comedy':['TV Comedies','Comedies'], 'Crime':['Crime TV Shows'], 'Documentary':['Documentaries'],\n",
    "                    'Drama':['TV Dramas', 'Dramas'],'Faith & Spirituality':['Faith and Spirituality'],'Game Shows':['Game Show / Competition'],\n",
    "                    'History':['Historical'], 'Horror': ['TV Horror','Horror Movies'],'International':['International Movies', 'International TV Shows'],\n",
    "                    'Kids':[\"Kids' TV\"],'LGBTQ':['LGBTQ Movies', 'LGBTQ+'],'Lifestyle':['Lifestyle & Culture'],'Mystery':['TV Mysteries'],\n",
    "                    'Music':['Music & Musicals', 'Music Videos and Concerts', 'Musical'],'Reality':[ 'Reality TV'],\n",
    "                    'Romance':['Romantic Movies','Romantic TV Shows'], 'Sports':['Sports Movies'],'Sci-Fi & Fantasy':['TV Sci-Fi & Fantasy'],\n",
    "                    'Stand Up':['Stand-Up Comedy','Stand-Up Comedy & Talk Shows'],'Thriller':['TV Thrillers','Thrillers']\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_col(df,dict_valores,col):\n",
    "    '''\n",
    "    df: dataframe\n",
    "    dict_valores: dict con su estructura = {valor_normalizado:valores_a_normalizar}\n",
    "    col: str(nombre de la columna)\n",
    "\n",
    "    Normaliza la columna col de df con los valores dados en dict_valores\n",
    "    '''\n",
    "\n",
    "    #itera sobre los valores de dict_valores\n",
    "    for key,valores in dict_valores.items():\n",
    "        #itera sobre los elementos en la columna \n",
    "        for str_valores in df[col]:\n",
    "            #itera sobre los valores de cada elemnto del dicionario\n",
    "            for val in valores:\n",
    "                #verifica si el valor esta en el elemento\n",
    "                if val in str_valores:\n",
    "                    #remplaza el valor normalizado\n",
    "                    df[col][df[col] == str_valores] = df[col][df[col] == str_valores].replace({str_valores:str_valores.replace(val,key)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    normalizar_col(df,valores_normalizar,'listed_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria_normalizadas =  valores_col([df_a,df_d,df_n,df_h],'listed_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Action', 'Action & Adventure', 'Adult Anime', 'Adventure',\n",
       "       'Animals & Nature', 'Anime', 'Anthology', 'Arthouse', 'Arts',\n",
       "       'Biographical', 'Black Stories', 'British TV Shows', 'Buddy',\n",
       "       'Cartoons', 'Children & Family Movies', 'Classic', 'Comedy',\n",
       "       'Coming of Age', 'Concert Film', 'Cooking & Food', 'Crime',\n",
       "       'Cult Movies', 'Dance', 'Disaster', 'Documentary', 'Docuseries',\n",
       "       'Drama', 'Entertainment', 'Faith & Spirituality', 'Family',\n",
       "       'Fantasy', 'Fitness', 'Game Shows', 'Health & Wellness', 'History',\n",
       "       'Horror', 'Independent Movies', 'International', 'Kids',\n",
       "       'Korean TV Shows', 'LGBTQ', 'Late Night', 'Latino', 'Lifestyle',\n",
       "       'Medical', 'Military and War', 'Movies', 'Music', 'Mystery',\n",
       "       'News', 'Parody', 'Police/Cop', 'Reality', 'Romance',\n",
       "       'Romantic Comedy', 'Sci-Fi & Fantasy', 'Science & Nature TV',\n",
       "       'Science & Technology', 'Science Fiction', 'Series', 'Sitcom',\n",
       "       'Sketch Comedy', 'Soap Opera / Melodrama',\n",
       "       'Spanish-Language TV Shows', 'Special Interest', 'Sports',\n",
       "       'Spy/Espionage', 'Stand Up', 'Stand Up & Talk Shows', 'Superhero',\n",
       "       'Survival', 'Suspense', 'TV Shows', 'Talk Show',\n",
       "       'Talk Show and Variety', 'Teen', 'Teen TV Shows', 'Thriller',\n",
       "       'Travel', 'Unscripted', 'Variety', 'Western',\n",
       "       'Young Adult Audience', 'and Culture'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoria_normalizadas.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de categorias se redujo de 120 a 84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lleno los datos faltantes con datos de las distintas plataformas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores de inteser segun los criterio ya mencionados son:<br>\n",
    "- duration(netflix:3,hulu:479)\n",
    "- cast(amazon:1233,disney:190,netflix:825,hulu:3037)\n",
    "- realise_year(completo)\n",
    "- list_in(completo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completar_col(df,columna,df_comprobar):\n",
    "    '''\n",
    "    df: dataframe que queremos completar\n",
    "    columna: str del la columna a revisar\n",
    "    df_comprobar: dataframe en que se va a comprobar si hay datos\n",
    "\n",
    "    Busca las peliculas que pertenecen a ambos dataframes, e itera sobre ellos para \n",
    "    completar los datos faltantes si es que en el valor de la columna dada es nulo en df\n",
    "    y no es nulo en df_comprobar\n",
    "    '''\n",
    "\n",
    "    #mascara para filtrar los titulos con nan en la columna\n",
    "    mask_nan = df[columna].isna() == True\n",
    "    # genero una serie con las pelicula que tengan nan o none ne la columna dada por parametro\n",
    "    films_nan = df['title'][mask_nan]\n",
    "    #genero una serie de los titulos presentes en ambos df \n",
    "    mask_comp = films_nan.isin(df_comprobar['title'])\n",
    "    film_comp = films_nan[mask_comp]\n",
    "    \n",
    "    #itero sobre los titulos que comparten ambos df\n",
    "    for title in film_comp:\n",
    "        valor_col_df = df[columna][df['title'] == title]\n",
    "        if valor_col_df.isnull().values:  \n",
    "            valor_col = df_comprobar[columna][df_comprobar['title'] == title]\n",
    "            if  not valor_col.isnull().values:\n",
    "                index = df[df['title'] == title].index\n",
    "                index_col= list(df_h[0:0]).index(columna)\n",
    "                df.iloc[index,index_col] = valor_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completar_df(df,lista_col,lista_df_comprobar):\n",
    "    '''\n",
    "    df: dataframe a completar\n",
    "    lista_col: lista de las columnas a completar\n",
    "    df_comprobar: dataframe con el que se quiere comprobar los datos faltantes\n",
    "\n",
    "    Usa la funcion complera_col par lleanr a df en las columnas dadas en lista_col\n",
    "    con los datos de los dataframes de lista_df_comprobar.\n",
    "    '''\n",
    "\n",
    "    for col in lista_col:\n",
    "        for df_com in lista_df_comprobar:\n",
    "            completar_col(df, col, df_com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Netflix y Hulu tienen valores faltantes en 'duration' y 'cast' uso la funcion completar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "completar_df(df_h,['duration','cast'],[df_a,df_d,df_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "completar_df(df_n,['duration','cast'],[df_a,df_d,df_h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Dysney+ y Amazon solo falta completar la columna cast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "completar_df(df_a,['cast'],[df_n,df_d,df_h])\n",
    "completar_df(df_d,['cast'],[df_n,df_a,df_h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificar a que plataforma pretenece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder identificar a que plataforma pertence le agrego a las plataformas una columna con el nombre de la platforma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "platformas = ['amazon','disney','netflix','hulu']\n",
    "for i,df in enumerate(dfs):\n",
    "    df['platform'] = np.array(platformas[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concateno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries = pd.concat([df_a,df_d,df_n,df_h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columnas sobrantres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino las columnas 'director','country','date_added','rating' y 'description' que no aporta a las query requeridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries.drop(['director', 'country', 'date_added','rating','description'],axis=1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lleno los valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries.fillna('sin datos',inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pongo en minuscula los valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas =['type', 'title', 'cast', 'listed_in']\n",
    "for col in columnas:\n",
    "    df_queries[col] = df_queries[col].apply(lambda x : x.lower())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimino los espacios al principio y final de los valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas =['type', 'title', 'cast', 'listed_in']\n",
    "for col in columnas:\n",
    "    df_queries[col] = df_queries[col].apply(lambda x : x.rstrip().lstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Conviene eliminar las peliculas o series duplicadas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de peliculas y seires repetidas son: 957\n",
      "El porcentaje de peliculas repetidas es : 0.041612314114270806\n"
     ]
    }
   ],
   "source": [
    "print('La cantidad de peliculas y seires repetidas son:',df_queries.shape[0]- df_queries['title'].unique().shape[0])\n",
    "print('El porcentaje de peliculas repetidas es :',((df_queries.shape[0] - df_queries['title'].unique().shape[0]) / df_queries.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las peliculas o series repetidas no son muy pocas en comparacion al total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporto el df_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporto el df_query y lo guardo en la carpeta 'Datasets' para ser utlizado por la api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries.to_csv('app/df_procesado.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
